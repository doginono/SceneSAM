from src.utils import backproject
import numpy as np
import cv2
import torch
import math
from scipy import signal
import torch.nn.functional as F 
import fpsample

def readDepth(filepath):
    depth = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)
    depth_data = depth.astype(np.float32) / 6553.5
    depth_data = torch.from_numpy(depth_data)
    return depth_data


def createMapping(
    ids1,
    backprojectedSamples,
    zg,
    Depthg,
):
    backprojectedSamples = backprojectedSamples.astype(int)
    # efficient
    # filter out samples outside of image bounds
    condition = (
        (backprojectedSamples[1, :] < 0)
        | (backprojectedSamples[0, :] < 0)
        | (backprojectedSamples[1, :] > 679)
        | (backprojectedSamples[0, :] > 1199)
    )
    filteredIndices = np.where(condition)
    filteredBackProj = backprojectedSamples[:, ~condition]
    #if outside filter
    if len(filteredBackProj[0]) == 0:
        return -1

    depthg = np.array(Depthg[filteredBackProj[1, :], filteredBackProj[0, :]])
    zg = np.delete(zg, filteredIndices)
    depthCheck = depthg - zg

    # depth check indices
    # if depth close enough
    indices = np.where(abs(depthCheck) < 0.1)
    filteredBackProj = filteredBackProj[:, indices]

    if filteredBackProj.size == 0:
        return -1
    ids1_elements = ids1[filteredBackProj[1, :], filteredBackProj[0, :]]
    array, counts = np.unique(ids1_elements, return_counts=True)

    idMostOccuring = int(array[np.argmax(counts)])
    #print(idMostOccuring)
    return idMostOccuring


def readImage(filepath):
    image = cv2.imread(filepath)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image


# check one class mapping
# behind or not checkdef create_complete_mapping_of_current_frame(
def checkIfInsideImage(
    backprojectedSamples,
    zg,
    Depthg,
):
    backprojectedSamples = backprojectedSamples.astype(int)
    # efficient
    # filter out samples outside of image bounds
    condition = (
        (backprojectedSamples[1, :] < 0)
        | (backprojectedSamples[0, :] < 0)
        | (backprojectedSamples[1, :] > 679)
        | (backprojectedSamples[0, :] > 1199)
    )
    filteredIndices = np.where(condition)
    filteredBackProj = backprojectedSamples[:, ~condition]
    
    depthg = np.array(Depthg[filteredBackProj[1, :], filteredBackProj[0, :]])
    zg = np.delete(zg, filteredIndices)
    depthCheck = depthg - zg

    indices = np.where(abs(depthCheck) < 0.1)
    filteredBackProj = filteredBackProj[:, indices]
    return filteredBackProj



def update_current_frame(curr_mask, id2id):
    """update curr_mask according to sampleFromCurrentMask

    Args:
        curr_mask (np.array): (W,H) with ids
        id2id (np.array): 1D array where at id2id[i] = value, means that the id i of the current frame has actual id value

    Return:
        np.array (W,H): updated mask
    """
    updated = curr_mask.copy()
    ids = np.unique(curr_mask)
    for id in ids:
        updated[curr_mask == id] = id2id[id]
    return updated


def create_complete_mapping_of_current_frame(
    ids_curr,
    curr_frame_number,
    frame_numbers,
    T,
    K,
    depths,
    segmentations,
    id_counter,
    points_per_instance=5,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    map = []
    Tf = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    unique_ids = np.unique(ids_curr).astype(int)
    max_id = np.max(unique_ids).astype(int)
    map = None
    for num in frame_numbers:
        Tg = T[num]
        # starts counting from 0 so the lenght is 1 more than the actual number of frames
        map_of_frame = np.ones(max_id + 1) * (-1)
        ids_past = segmentations[int(num / points_per_instance)]
        # this gets overwrittâ€šen
        depthg = readDepth(depths[num])
        samplesFromCurrentMask = backproject.sample_from_instances(
            ids_curr, np.max(unique_ids) + 1, points_per_instance
        )
        for instance in unique_ids:
            current = samplesFromCurrentMask[:, :, instance]

            backprojectedSamples, zg = backproject.backproject(
                current, Tf, Tg, K, depthf
            )
            # this overwrites the depthg therefore I calculate it in actual_id # depthg
            actual_id = createMapping(
                ids_past,
                backprojectedSamples,
                zg,
                depthg,
            )
            if actual_id == -1:
                actual_id = id_counter
                id_counter += 1
            map_of_frame[
                instance
            ] = actual_id  # at index i of map_of_frame is the actual id of the instance i in the current frame
        if map is None:
            map = map_of_frame[None]
        else:
            np.concatenate([map, map_of_frame[None]], axis=0)
    map = combineMaps(
        map.T
    )  # at index i of map.T are the actual ids of the instance i according to the past frames
    return map, id_counter


def createReverseMapping(
    ids_curr,
    curr_frame_number,
    earlier_frame_numbers,
    T,
    K,
    depths,
    segmentations,
    id_counter,
    predictor,
    points_per_instance=5,
    current_frame=None,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    map = []
    T_current = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    unique_ids = np.unique(segmentations[0]).astype(int)
    max_id = np.max(unique_ids).astype(int)
    masks = np.full((current_frame.shape[0], current_frame.shape[1]), -1)
    #for num in earlier_frame_numbers:
    for num in earlier_frame_numbers:
        T_earlier = T[num]
        # starts counting from 0 so the lenght is 1 more than the actual number of frames
        ids_past = segmentations[-1]

        # Ground truth depth
        depthEarlier = readDepth(depths[num])
        samplesFromEarlier = backproject.sample_from_instances(
            ids_past, np.max(unique_ids) + 1, points_per_instance
        )
        predictor.set_image(current_frame)
        print(unique_ids)
        for instance in unique_ids:
            earlierFrame = samplesFromEarlier[:, :, instance]
                
            frontProjectedSamples, projDepth = backproject.frontProject(
                earlierFrame, T_current,T_earlier, K, depthEarlier
            )
            #print(frontProjectedSamples)

            mask, _, _ = predictor.predict(
                point_coords=np.array(list(zip(frontProjectedSamples[0].tolist(), frontProjectedSamples[1].tolist()))),
                point_labels=len(frontProjectedSamples[0]) * [1],
                #mask_input = logits[np.argmax(scores), :, :]  # Choose the model's best mask
                multimask_output=False,
            )
            #print(mask.shape)
            masks[mask.squeeze()] = instance
            # this overwrites the depthg therefore I calculate it in actual_id # depthg
    counter=1
    '''
    while np.isin(-1, masks):
        indices= np.where(masks==-1)
        indices=np.dstack(indices)
        print(indices)
        random_index=indices[np.random.choice(len(indices))]
        print(random_index)
        mask, _, _ = predictor.predict(
            point_coords=np.array(random_index),
            point_labels=len(frontProjectedSamples[0]) * [1],
            multimask_output=False,
        )
        #print(mask.shape)
        #masks[mask.squeeze()] = instance
        masks[random_index] = max_id + counter
        counter+=1
        #print("Negative")
    '''
        
        
    return masks

#sample from earlier frames and predict 
def createReverseMappingCombined(
    curr_frame_number,
    T,
    K,
    depths,
    id_counter,
    predictor,
    points_per_instance=5,
    current_frame=None,
    samples=None,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    T_current = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    masks = np.full((current_frame.shape[0], current_frame.shape[1]), -1)
    
    predictor.set_image(current_frame)
    
    #projected to current camera frame, they also have ids
    frontProjectedSamples, projDepth = backproject.camProject(
        samples, T_current, K
    )
    
    frontProjectedSamples = checkIfInsideImage(frontProjectedSamples, projDepth, depthf)
    #check if all points lie on the same but different mask
    unique_ids = np.unique(samples[2:,:].astype(int))
    unique_ids = unique_ids[::-1]
    
    count=0
    #import matplotlib.pyplot as plt
    
    print("unique_ids", unique_ids)
    for instance in unique_ids:
        #print(instance)
        #sample same id points from from frontProjectedSamples
        filtre = (frontProjectedSamples[2,:,:] == instance)
        #print(count,frontProjectedSamples.shape)
        instanceId = frontProjectedSamples[:, filtre]
        other_instances_mask = (frontProjectedSamples[2,:,:] != instance)
        #otherInstancesId = frontProjectedSamples[:, other_instances_mask]        #print(count,instanceId.shape)
        count+=1
        if instanceId.size is not 0 and instanceId[2,0]>=0:
           
            theRelevant=np.array(list(zip(instanceId[0].tolist(), instanceId[1].tolist())))
            #nonRelevant=np.array(list(zip(otherInstancesId[0].tolist(), otherInstancesId[1].tolist())))
            fps=fpsample.fps_sampling(theRelevant, min(points_per_instance,len(theRelevant)))
            #fpsNon=fpsample.fps_sampling(nonRelevant, 10)
            sampledPositive=[1]*len(fps) 
            #np.concatenate((theRelevant[fps],nonRelevant[fpsNon]))
            #bumbum.extend([0]*len(nonRelevant[fpsNon]))
            mask, _, _ = predictor.predict(
                point_coords=theRelevant[fps],
                point_labels=sampledPositive,
                multimask_output=False,
            )
            '''
            # coarse to fine
            # backproject majority vote
            # when with automaticsam generator ratio of in points!!!
            # reset the samples 
            " After creating the mask backproject all ids into it and give according to the projected majority vote "
            #check if inside mask
            #take majority vote
            if instance==2:
                plt.figure(figsize=(20,20))
                plt.imshow(current_frame)
                for i in range(instanceId.shape[1]):
                    #print(instanceId[0,i],instanceId[1,i])
                    plt.scatter(instanceId[0,i],instanceId[1,i],c="red",s=500,marker='o')
            
                plt.axis('off')
                plt.show()'''
            masks[mask.squeeze()] = instance
    
    unique_ids = np.unique(masks).astype(int)
    max_id = id_counter#np.max(unique_ids).astype(int)
    
    #sample from the right side
   
    nb_channels = 1
    h, w = 40, 40
    weights = torch.ones(h, w)
    weights = weights.view(1, 1, h, w).repeat(1, nb_channels, 1, 1).to("cuda")
    torch_masks=torch.from_numpy(masks).float().to("cuda")
    result = F.conv2d(torch_masks.unsqueeze(0), weights,padding="same")
    result = result.cpu().numpy()  # convert to numpy array
    result=result.squeeze()
    print("result.shape",result.shape)
    indices = np.array(np.where(result == ((h*w)*-1))).T
    print("indices.shape",indices.shape)
    
    counter=0
    if len(indices)>0:
        counter=1
        
        random_index = indices[np.random.choice(len(indices))]
        point_coords = np.array([random_index[1],random_index[0]])
        point_coords = point_coords.reshape(1, -1)
        print(point_coords)
        mask, _, _ = predictor.predict(
            point_coords=point_coords,
            point_labels=np.array([1]),
            multimask_output=False,
        )
        masks[mask.squeeze()] = max_id + counter
        #need to sample more in the first time I found the new id
        """plt.figure(figsize=(20,20))
        plt.imshow(current_frame)
        #print(instanceId[0,i],instanceId[1,i])
        plt.scatter(random_index[1],random_index[0],c="yellow",s=500,marker='o')
        plt.axis('off')
        plt.show()"""
        oneNewMask=masks.copy()
        oneNewMask[oneNewMask!=max_id + counter]=-1
        #print("onemask",np.unique(oneNewMask))
        samplesFromCurrent = sample_from_instances_with_ids(
            oneNewMask, 
            max_id + counter, 
            points_per_instance=100
        )
        
        realWorldProjectCurr = backproject.realWorldProject(
            samplesFromCurrent[:2,:],T[curr_frame_number], K, depthf
        )
        realWorldProjectCurr = np.concatenate((realWorldProjectCurr,samplesFromCurrent[2:,:]),axis=0)
        samples=np.concatenate((samples,realWorldProjectCurr),axis=1)
        
    
    for i in range(max_id + counter):
        num_elements = np.count_nonzero(masks == i)
        if num_elements < 1600:
            masks[masks == i] = -2
    
    max_id = max_id + counter
    
    samplesFromCurrent = sample_from_instances_with_ids(
        masks, 
        max_id + counter, 
        points_per_instance=10
    )
    
    realWorldProjectCurr = backproject.realWorldProject(
        samplesFromCurrent[:2,:],T[curr_frame_number], K, depthf
    )
    realWorldProjectCurr = np.concatenate((realWorldProjectCurr,samplesFromCurrent[2:,:]),axis=0)
    samples=np.concatenate((samples,realWorldProjectCurr),axis=1)
    
    return masks,samples


def create_complete_mapping(
    store_path, every_nth_frame, T, K, directory, points_per_instance=5
):
    pass

# when combining the maps, For example we look into earlier 0 5 10 15 20 25 30th frame
# New object recognized in 20th frame, also in 25th frame, 
# Bu when
def combineMaps(map):
    # reduce map on axis 1 end check if all elements are the same or -1
    if map.shape[1] != 1:
        for i in range(map.shape[0]):
            tmp = map[i][map[i] != -1]
            assert ~(np.all(tmp[0] - tmp == 0)), "mapping is not consistent"
    return map.T[0]

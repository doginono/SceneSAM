{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaolin as kal\n",
    "import torch\n",
    "import trimesh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_cloud(file_name):\n",
    "    \"\"\" Load a mesh and sample points on its surface. \"\"\"\n",
    "    mesh = trimesh.load(file_name)  # Sample 10,000 points on the surface\n",
    "    return mesh.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point clouds\n",
    "pt_gt = torch.tensor(load_point_cloud('/home/rozenberszki/scene0423_02/scene0423_02_vh_clean_2.ply'))\n",
    "#pt_comp = torch.tensor(load_point_cloud(\"/home/rozenberszki/project/wsnsl/output/Own/office4/mesh/final_mesh_color.ply\")).to('cuda')\n",
    "pt_comp = torch.tensor(load_point_cloud('/home/rozenberszki/project/wsnsl/output/scannet/scans/scene0423_02_panoptic/mesh/final_mesh_color.ply'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Load or create point clouds\n",
    "# Convert the tensor to a numpy array\n",
    "pt_gt_np = pt_gt.cpu().numpy()\n",
    "\n",
    "# Create an Open3D point cloud\n",
    "pt_gt_o3d = o3d.geometry.PointCloud()\n",
    "pt_gt_o3d.points = o3d.utility.Vector3dVector(pt_gt_np)\n",
    "\n",
    "pt_comp_np = pt_gt.cpu().numpy()\n",
    "\n",
    "# Create an Open3D point cloud\n",
    "pt_comp_o3d = o3d.geometry.PointCloud()\n",
    "pt_comp_o3d.points = o3d.utility.Vector3dVector(pt_comp_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply ICP\n",
    "threshold = 0.0002  # Set a threshold for point correspondence\n",
    "trans_init = np.eye(4)  # Assume an initial guess of identity matrix\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    pt_gt_o3d, pt_comp_o3d, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "\n",
    "# Transform the second point cloud for alignment\n",
    "pt_comp_o3d_aligned = pt_comp_o3d.transform(reg_p2p.transformation)\n",
    "\n",
    "# Now pcd1 and pcd2 are aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the Open3D point cloud to a numpy array\n",
    "pt_comp_aligned = np.asarray(pt_comp_o3d.points)\n",
    "\n",
    "# Convert the numpy array to a tensor\n",
    "pt_comp_aligned = torch.tensor(pt_comp_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3627, 1.4352, 0.0162], dtype=torch.float64),\n",
       " tensor([ 1.2500,  1.3500, -0.0400], dtype=torch.float64),\n",
       " tensor([1.3627, 1.4352, 0.0162], dtype=torch.float64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_gt.min(dim=0)[0], pt_comp.min(dim=0)[0], pt_comp_aligned.min(dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pt_gt.unsqueeze(0).to('cuda')\n",
    "y = pt_comp.unsqueeze(0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# p1 and p2 are your point clouds\n",
    "d1 = kal.metrics.pointcloud.chamfer_distance(x, y)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = kal.metrics.pointcloud.chamfer_distance(y, x)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2207, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chamfer_dist = torch.mean(d1) + torch.mean(d2)\n",
    "chamfer_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "length = 100\n",
    "line = \"-\" * length\n",
    "print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rozenberszki/project/replica_v2/office_4/habitat/mesh_semantic.ply'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepath_gt  = '/home/rozenberszki/project/replica_v2/{scene}/habitat/mesh_semantic.ply'\n",
    "basepath_gt.format(scene='office_4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10000, 3]), torch.Size([1, 10000, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32).to('cuda')\n",
    "y = torch.tensor(y, dtype=torch.float32).to('cuda')\n",
    "x = x.unsqueeze(0)\n",
    "y = y.unsqueeze(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10000, 3]), torch.Size([1, 10000, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_size = x.size(0)\n",
    "y_size = y.size(0)\n",
    "x_repeat = x.repeat(y_size, 1, 1)\n",
    "y_repeat = y.repeat(1, x_size, 1)\n",
    "x_repeat.shape, y_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = torch.pow(x_repeat - y_repeat, 2).sum(2)\n",
    "dist_x_to_y = torch.min(differences, 2)[0]\n",
    "dist_y_to_x = torch.min(differences, 1)[0]\n",
    "\n",
    "chamfer_dist = torch.mean(dist_x_to_y) + torch.mean(dist_y_to_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1279408/252467029.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate Chamfer Distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchamfer_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Chamfer Distance: {dist}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1279408/1397780976.py\u001b[0m in \u001b[0;36mchamfer_distance\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdifferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_repeat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_repeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdist_x_to_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdist_y_to_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate Chamfer Distance\n",
    "dist = chamfer_distance(points1, points2)\n",
    "print(f\"Chamfer Distance: {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsnsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

from backproject import *
import numpy as np
import cv2
import torch

import backproject


def readDepth(filepath):
    depth = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)
    depth_data = depth.astype(np.float32) / 6553.5
    depth_data = torch.from_numpy(depth_data)
    return depth_data


def createMapping(
    ids1,
    backprojectedSamples,
    zg,
    Depthg,
):
    backprojectedSamples = backprojectedSamples.astype(int)
    # efficient
    # filter out samples outside of image bounds
    condition = (
        (backprojectedSamples[1, :] < 0)
        | (backprojectedSamples[0, :] < 0)
        | (backprojectedSamples[1, :] > 679)
        | (backprojectedSamples[0, :] > 1199)
    )
    filteredIndices = np.where(condition)
    filteredBackProj = backprojectedSamples[:, ~condition]
    #if outside filter
    if len(filteredBackProj[0]) == 0:
        return -1

    depthg = np.array(Depthg[filteredBackProj[1, :], filteredBackProj[0, :]])
    zg = np.delete(zg, filteredIndices)
    depthCheck = depthg - zg

    # depth check indices
    # if depth close enough
    indices = np.where(abs(depthCheck) < 0.1)
    filteredBackProj = filteredBackProj[:, indices]

    if filteredBackProj.size == 0:
        return -1
    ids1_elements = ids1[filteredBackProj[1, :], filteredBackProj[0, :]]
    array, counts = np.unique(ids1_elements, return_counts=True)

    idMostOccuring = int(array[np.argmax(counts)])
    #print(idMostOccuring)
    return idMostOccuring


def readImage(filepath):
    image = cv2.imread(filepath)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image


# check one class mapping
# behind or not checkdef create_complete_mapping_of_current_frame(
def checkIfInsideImage(
    backprojectedSamples,
    zg,
    Depthg,
):
    backprojectedSamples = backprojectedSamples.astype(int)
    # efficient
    # filter out samples outside of image bounds
    condition = (
        (backprojectedSamples[1, :] < 0)
        | (backprojectedSamples[0, :] < 0)
        | (backprojectedSamples[1, :] > 679)
        | (backprojectedSamples[0, :] > 1199)
    )
    filteredIndices = np.where(condition)
    filteredBackProj = backprojectedSamples[:, ~condition]
    
    depthg = np.array(Depthg[filteredBackProj[1, :], filteredBackProj[0, :]])
    zg = np.delete(zg, filteredIndices)
    depthCheck = depthg - zg

    indices = np.where(abs(depthCheck) < 0.1)
    filteredBackProj = filteredBackProj[:, indices]
    return filteredBackProj



def update_current_frame(curr_mask, id2id):
    """update curr_mask according to sampleFromCurrentMask

    Args:
        curr_mask (np.array): (W,H) with ids
        id2id (np.array): 1D array where at id2id[i] = value, means that the id i of the current frame has actual id value

    Return:
        np.array (W,H): updated mask
    """
    updated = curr_mask.copy()
    ids = np.unique(curr_mask)
    for id in ids:
        updated[curr_mask == id] = id2id[id]
    return updated


def create_complete_mapping_of_current_frame(
    ids_curr,
    curr_frame_number,
    frame_numbers,
    T,
    K,
    depths,
    segmentations,
    id_counter,
    points_per_instance=5,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    map = []
    Tf = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    unique_ids = np.unique(ids_curr).astype(int)
    max_id = np.max(unique_ids).astype(int)
    map = None
    for num in frame_numbers:
        Tg = T[num]
        # starts counting from 0 so the lenght is 1 more than the actual number of frames
        map_of_frame = np.ones(max_id + 1) * (-1)
        ids_past = segmentations[int(num / points_per_instance)]
        # this gets overwrittâ€šen
        depthg = readDepth(depths[num])
        samplesFromCurrentMask = sample_from_instances(
            ids_curr, np.max(unique_ids) + 1, points_per_instance
        )
        for instance in unique_ids:
            current = samplesFromCurrentMask[:, :, instance]

            backprojectedSamples, zg = backproject.backproject(
                current, Tf, Tg, K, depthf
            )
            # this overwrites the depthg therefore I calculate it in actual_id # depthg
            actual_id = createMapping(
                ids_past,
                backprojectedSamples,
                zg,
                depthg,
            )
            if actual_id == -1:
                actual_id = id_counter
                id_counter += 1
            map_of_frame[
                instance
            ] = actual_id  # at index i of map_of_frame is the actual id of the instance i in the current frame
        if map is None:
            map = map_of_frame[None]
        else:
            np.concatenate([map, map_of_frame[None]], axis=0)
    map = combineMaps(
        map.T
    )  # at index i of map.T are the actual ids of the instance i according to the past frames
    return map, id_counter


def createReverseMapping(
    ids_curr,
    curr_frame_number,
    earlier_frame_numbers,
    T,
    K,
    depths,
    segmentations,
    id_counter,
    predictor,
    points_per_instance=5,
    current_frame=None,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    map = []
    T_current = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    unique_ids = np.unique(segmentations[0]).astype(int)
    max_id = np.max(unique_ids).astype(int)
    masks = np.full((current_frame.shape[0], current_frame.shape[1]), -1)
    #for num in earlier_frame_numbers:
    for num in earlier_frame_numbers:
        T_earlier = T[num]
        # starts counting from 0 so the lenght is 1 more than the actual number of frames
        ids_past = segmentations[-1]

        # Ground truth depth
        depthEarlier = readDepth(depths[num])
        samplesFromEarlier = sample_from_instances(
            ids_past, np.max(unique_ids) + 1, points_per_instance
        )
        predictor.set_image(current_frame)
        
        for instance in unique_ids:
            earlierFrame = samplesFromEarlier[:, :, instance]
                
            frontProjectedSamples, projDepth = backproject.frontProject(
                earlierFrame, T_current,T_earlier, K, depthEarlier
            )
            #print(frontProjectedSamples)

            mask, _, _ = predictor.predict(
                point_coords=np.array(list(zip(frontProjectedSamples[0].tolist(), frontProjectedSamples[1].tolist()))),
                point_labels=len(frontProjectedSamples[0]) * [1],
                #mask_input = logits[np.argmax(scores), :, :]  # Choose the model's best mask
                multimask_output=False,
            )
            #print(mask.shape)
            masks[mask.squeeze()] = instance
            # this overwrites the depthg therefore I calculate it in actual_id # depthg
    counter=1
    '''
    while np.isin(-1, masks):
        indices= np.where(masks==-1)
        indices=np.dstack(indices)
        print(indices)
        random_index=indices[np.random.choice(len(indices))]
        print(random_index)
        mask, _, _ = predictor.predict(
            point_coords=np.array(random_index),
            point_labels=len(frontProjectedSamples[0]) * [1],
            multimask_output=False,
        )
        #print(mask.shape)
        #masks[mask.squeeze()] = instance
        masks[random_index] = max_id + counter
        counter+=1
        #print("Negative")
    '''
        
        
    return masks

#sample from earlier frames and predict 
def createReverseMappingCombined(
    curr_frame_number,
    T,
    K,
    depths,
    id_counter,
    predictor,
    points_per_instance=5,
    current_frame=None,
    samples=None,
    bbox=None,
):
    """creates a mapping of the current ids to the actual ids according to the past frames;
    This is implemented in a way, that some of the function arguments can be replaced by the frame_reader class from nice_slam,
    in this frame_reader we can also distiguish whether the id will be generated by SAM on the fly or if we have generated them in advance

    Args:
        ids_curr (_type_): _description_
        curr_frame_number (int): current frame number
        frame_numbers (np.array): frame numbers, which will be used for the backprojection
        T (list): list of extrinsic camera poses
        K (np.array): intrinsic camera matrix
        depths (list): contains all depthspath of the frames
        frames (list): contains all rgb image paths
        segmentations (list): contains all segmentations of seen frames
        id_counter (int): the current smallest free id.
        points_per_instance (int, optional): number of points per instance. Defaults to 5.

    Return:
        np.array (2, #num ids in curr_mask): mapping of the current ids to the actual ids according to the past frames
    """
    '''T_current = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    
    masks = np.full((current_frame.shape[0], current_frame.shape[1]), -1)'''
    #for num in earlier_frame_numbers:
    #print("earlierFrame", earlier_frame_numbers)
    T_current = T[curr_frame_number]
    depthf = readDepth(depths[curr_frame_number])
    masks = np.full((current_frame.shape[0], current_frame.shape[1]), -1)
    bboxCam = None
    '''samplesFromEarlier = sample_from_instances(
            ids_past, np.max(unique_ids) + 1, points_per_instance
        )
        '''
    
    predictor.set_image(current_frame)
    #projected to current camera frame, they also have ids
    frontProjectedSamples, projDepth = backproject.camProject(
        samples, T_current, K
    )
    
    frontProjectedSamples = checkIfInsideImage(frontProjectedSamples, projDepth, depthf)
    
    unique_ids = np.unique(samples[2:,:].astype(int))
    #print("unique_ids", unique_ids)
    #print("frontProjectedSamples", frontProjectedSamples.shape)
    count=0
    import matplotlib.pyplot as plt
    
    for instance in unique_ids:
        #sample same id points from from frontProjectedSamples
        filtre = (frontProjectedSamples[2,:,:] == instance)
        #print(count,frontProjectedSamples.shape)
        instanceId = frontProjectedSamples[:, filtre]
        #print(count,instanceId.shape)
        count+=1
        #print(bbox)
        '''if instance in bbox:
            bboxCam, _= backproject.camProjectBoundingBoxes(bbox[instance],T_current,K)'''
            #bboxCam2, _= backproject.camProject(bbox[instance][:,1],T_current,K)
        if instanceId.size is not 0:
            mask, _, _ = predictor.predict(
                point_coords=np.array(list(zip(instanceId[0].tolist(), instanceId[1].tolist()))),
                point_labels=len(instanceId[0]) * [1],
                multimask_output=False,
            )
            
            if instance==1:
                plt.figure(figsize=(20,20))
                plt.imshow(current_frame)
                for i in range(instanceId.shape[1]):
                    #print(instanceId[0,i],instanceId[1,i])
                    plt.scatter(instanceId[0,i],instanceId[1,i],c="red",s=500,marker='o')
            
                plt.axis('off')
                plt.show()
            masks[mask.squeeze()] = instance

            
    counter=1
    
    
    unique_ids = np.unique(masks).astype(int)
    
    samplesFromCurrent = sample_from_instances_with_ids(
        masks, 
        len(unique_ids), 
        points_per_instance=points_per_instance
    )
    
    realWorldProjectCurr = backproject.realWorldProject(
        samplesFromCurrent[:2,:],T[curr_frame_number], K, depthf
    )
    realWorldProjectCurr = np.concatenate((realWorldProjectCurr,samplesFromCurrent[2:,:]),axis=0)
    samples=np.concatenate((samples,realWorldProjectCurr),axis=1)
    
    # print("samples", samples.shape)
    '''
    unique_ids = np.unique(masks).astype(int)
    max_id = np.max(unique_ids).astype(int)
    if masks[masks==-1].size is not 0:
        while np.isin(-1, masks):
            indices = np.array(np.where(masks == -1)).T
            random_index = indices[np.random.choice(len(indices))]
            mask, _, _ = predictor.predict(
                point_coords=np.array([random_index]),
                point_labels=[1],
                multimask_output=False,
            )
            masks[mask.squeeze()] = max_id + counter
            counter += 1
            print(max_id + counter)
            print(np.count_nonzero(masks == -1))
            #print("Negative")'''
    return masks,samples


def create_complete_mapping(
    store_path, every_nth_frame, T, K, directory, points_per_instance=5
):
    pass

# when combining the maps, For example we look into earlier 0 5 10 15 20 25 30th frame
# New object recognized in 20th frame, also in 25th frame, 
# Bu when
def combineMaps(map):
    # reduce map on axis 1 end check if all elements are the same or -1
    if map.shape[1] != 1:
        for i in range(map.shape[0]):
            tmp = map[i][map[i] != -1]
            assert ~(np.all(tmp[0] - tmp == 0)), "mapping is not consistent"
    return map.T[0]

dataset: 'scannet_orig_every'
tracking:
  vis_freq: 50
  vis_inside_freq: 25
  ignore_edge_W: 20
  ignore_edge_H: 20
  seperate_LR: False
  const_speed_assumption: True
  lr: 0.0005      
  pixels: 1000
  iters: 40
  gt_camera: False

rendering:
  semantic_occupancy_multiplier: 10

Segmenter:
  samplePixelFarther: 0
  normalizePointNumber: 10
  depthCondition: 0.5 #0.005 #0.0
  border: 0
  smallestMaskSize: 5000 # 10000
  full_slam: True # if True, then segmentation and train on segmentations is used in parallel else it is used in retrospect (we call it post-processing)
  mask_generator: False # always False -> delete later
  #store: False    #if use_store True then store and store_vis have no effect
  use_stored: False
  store_vis: True
  store_vis_freq: 100 # not implemented yet
  num_clusters: 5
  border: 0
  overlap: 0.4 # makes more stable
  relevant: 0.3
  merging_parameter: 7 # if it really is the same object, then it should not have any problems eating the other mask even if for 10 frames
  every_frame: 6
  verbose: True
  hit_percent: 0.4
meshing:
  eval_rec: True
  resolution: 256
mapping:
  first_min_area: 5000
  use_vis: True
  no_vis_on_first_frame: True
  every_frame: 2
  points_per_instance: 4
  vis_freq: 200
  vis_inside_freq: 61
  vis_offset: 0 #we take the current frame - vis_offset for visualization #should not work at the moment
  use_mesh: True #whether to generate mesh during training, the creation of thefinal mesh only depends ecal_rec
  no_mesh_on_first_frame: True
  mesh_freq: 80
  ckpt_freq: 200
  keyframe_every: 24
  mapping_window_size: 10
  pixels: 5000
  iters_first: 1200 #finetune
  iters: 60 #finetune
  w_color_loss: 0.2 #maybe finetune
  w_semantic_loss: 10 #finetuneS
  middle_iter_ratio: 0.4 #0.4 #finetune
  fine_iter_ratio: 0.6 #0.6 #finetune
  semantic_iter_ratio: 0.4 #0.4 #finetune
cam: 
  poseScale: 1
  H: 480 
  W: 640
  fx: 577.590698
  fy: 578.729797
  cx: 318.905426
  cy: 242.683609
  png_depth_scale: 1000. #for depth image in png format
